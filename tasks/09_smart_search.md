# Task 09: Smart Search - T√≠ch H·ª£p T√¨m Ki·∫øm Ng·ªØ Nghƒ©a ‚úÖ ƒê√É HO√ÄN TH√ÄNH

## M·ª•c Ti√™u

T√≠ch h·ª£p t√≠nh nƒÉng **Smart Search** (t√¨m ki·∫øm th√¥ng minh) v√†o h·ªá th·ªëng recommendation service, s·ª≠ d·ª•ng PhoBERT embeddings ƒë√£ ƒë∆∞·ª£c t·∫°o ra t·ª´ c√°c task tr∆∞·ªõc. T√≠nh nƒÉng n√†y cho ph√©p ng∆∞·ªùi d√πng t√¨m ki·∫øm s·∫£n ph·∫©m b·∫±ng ng√¥n ng·ªØ t·ª± nhi√™n (ti·∫øng Vi·ªát) thay v√¨ ch·ªâ d·ª±a tr√™n keyword matching truy·ªÅn th·ªëng.

---

## ‚úÖ Tr·∫°ng Th√°i Tri·ªÉn Khai (Th√°ng 11/2025)

**C√°c th√†nh ph·∫ßn ƒë√£ ho√†n th√†nh**:

| Th√†nh ph·∫ßn | File | Tr·∫°ng th√°i |
|------------|------|------------|
| QueryEncoder | `service/search/query_encoder.py` | ‚úÖ Ho√†n th√†nh |
| SearchIndex | `service/search/search_index.py` | ‚úÖ Ho√†n th√†nh |
| SmartSearchService | `service/search/smart_search.py` | ‚úÖ Ho√†n th√†nh |
| API Endpoints | `service/api.py` | ‚úÖ Ho√†n th√†nh |
| Test Script | `service/search/test_search_features.py` | ‚úÖ Ho√†n th√†nh |

---

## üìä Ph·ª• Thu·ªôc D·ªØ Li·ªáu

**Embeddings ƒë√£ c√≥ s·∫µn t·ª´ c√°c tasks tr∆∞·ªõc**:
- **Product Embeddings**: `data/processed/content_based_embeddings/product_embeddings.pt`
  - Ch·ª©a BERT embeddings cho ~2,200 products
  - Dimension: 768 (PhoBERT-base)
  - Pre-normalized vectors cho fast cosine similarity
- **PhoBERTEmbeddingLoader** (Task 05/08): Singleton class ƒë√£ implement loading v√† similarity computation

**L·ª£i th·∫ø so v·ªõi keyword search truy·ªÅn th·ªëng**:
- Hi·ªÉu ng·ªØ nghƒ©a ti·∫øng Vi·ªát (synonyms, paraphrases)
- X·ª≠ l√Ω vi·∫øt t·∫Øt v√† bi·∫øn th·ªÉ t·ª´ v·ª±ng (srm ‚Üí s·ªØa r·ª≠a m·∫∑t, kcn ‚Üí kem ch·ªëng n·∫Øng)
- T√¨m ki·∫øm theo intent/concept, kh√¥ng ch·ªâ exact match

---

## üéØ C√°c Tr∆∞·ªùng H·ª£p S·ª≠ D·ª•ng

### Use Case 1: T√¨m Ki·∫øm S·∫£n Ph·∫©m
```
User: "t√¨m kem d∆∞·ª°ng da cho da d·∫ßu m·ª•n"
‚Üí Semantic search: t√¨m products c√≥ embeddings g·∫ßn v·ªõi query embedding
‚Üí Return: kem tr·ªã m·ª•n, gel ki·ªÉm so√°t d·∫ßu, serum BHA, etc.
```

### Use Case 2: T√¨m S·∫£n Ph·∫©m T∆∞∆°ng T·ª±
```
User: "s·∫£n ph·∫©m t∆∞∆°ng t·ª± [product_id=123]"
‚Üí Item-item similarity t·ª´ PhoBERT embeddings
‚Üí Return: top-K similar products
```

### Use Case 3: T√¨m Theo H·ªì S∆° Ng∆∞·ªùi D√πng
```
User v·ªõi l·ªãch s·ª≠: [product_1, product_2, product_3]
‚Üí T√≠nh user profile embedding t·ª´ l·ªãch s·ª≠
‚Üí Return: products t∆∞∆°ng t·ª± v·ªÅ semantic v·ªõi s·ªü th√≠ch
```

### Use Case 4: Hybrid Search (Thu·ªôc T√≠nh + Ng·ªØ Nghƒ©a)
```
User: "kem ch·ªëng n·∫Øng cho da nh·∫°y c·∫£m"
Filter: brand='Innisfree', max_price=500000
‚Üí Filter theo thu·ªôc t√≠nh tr∆∞·ªõc
‚Üí Rank theo embedding similarity
‚Üí Return: filtered & ranked products
```

---

## üèóÔ∏è T·ªïng Quan Ki·∫øn Tr√∫c

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Smart Search Service                      ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ  QueryEncoder   ‚îÇ  ‚îÇ   SearchIndex   ‚îÇ  ‚îÇ PhoBERT      ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  ‚îÇ  ‚îÇ   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ   ‚îÇ  ‚îÇ Loader       ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Singleton    ‚îÇ  ‚îÇ  ‚Ä¢ Exact search ‚îÇ  ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Vietnamese   ‚îÇ  ‚îÇ  ‚Ä¢ FAISS ANN    ‚îÇ  ‚îÇ ‚Ä¢ Embeddings ‚îÇ ‚îÇ
‚îÇ  ‚îÇ    preprocessing‚îÇ  ‚îÇ  ‚Ä¢ Metadata     ‚îÇ  ‚îÇ ‚Ä¢ Similarity ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ LRU Cache    ‚îÇ  ‚îÇ    filtering    ‚îÇ  ‚îÇ ‚Ä¢ Profile    ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Batch encode ‚îÇ  ‚îÇ  ‚Ä¢ Thread-safe  ‚îÇ  ‚îÇ   compute    ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ           ‚îÇ                    ‚îÇ                   ‚îÇ         ‚îÇ
‚îÇ           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îÇ
‚îÇ                                ‚îÇ                             ‚îÇ
‚îÇ                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                 ‚îÇ
‚îÇ                    ‚îÇ  SmartSearchService   ‚îÇ                 ‚îÇ
‚îÇ                    ‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ    ‚îÇ                 ‚îÇ
‚îÇ                    ‚îÇ  ‚Ä¢ search()           ‚îÇ                 ‚îÇ
‚îÇ                    ‚îÇ  ‚Ä¢ search_similar()   ‚îÇ                 ‚îÇ
‚îÇ                    ‚îÇ  ‚Ä¢ search_by_profile()‚îÇ                 ‚îÇ
‚îÇ                    ‚îÇ  ‚Ä¢ Multi-signal rerank‚îÇ                 ‚îÇ
‚îÇ                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                 ‚îÇ
‚îÇ                                ‚îÇ                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                 ‚îÇ
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ      API Endpoints      ‚îÇ
                    ‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ   ‚îÇ
                    ‚îÇ  POST /search           ‚îÇ
                    ‚îÇ  POST /search/similar   ‚îÇ
                    ‚îÇ  POST /search/profile   ‚îÇ
                    ‚îÇ  GET  /search/filters   ‚îÇ
                    ‚îÇ  GET  /search/stats     ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Th√†nh Ph·∫ßn 1: QueryEncoder ‚úÖ

### Module: `service/search/query_encoder.py`

**M√¥ t·∫£**: Singleton encoder ƒë·ªÉ chuy·ªÉn ƒë·ªïi text queries th√†nh embeddings s·ª≠ d·ª•ng PhoBERT.

#### T√≠nh nƒÉng ch√≠nh:
1. **Singleton pattern**: Thread-safe, ch·ªâ load model m·ªôt l·∫ßn
2. **Vietnamese preprocessing**: M·ªü r·ªông vi·∫øt t·∫Øt, chu·∫©n h√≥a text
3. **LRU Cache**: Cache embeddings ƒë·ªÉ tƒÉng t·ªëc queries l·∫∑p l·∫°i
4. **Batch encoding**: Encode nhi·ªÅu queries c√πng l√∫c hi·ªáu qu·∫£

```python
class QueryEncoder:
    """
    Encode text queries to embeddings using PhoBERT.
    
    Features:
    - Lazy loading of PhoBERT model
    - Query embedding caching (LRU)
    - Batch encoding for efficiency
    - Vietnamese text preprocessing with abbreviation expansion
    
    Example:
        >>> encoder = QueryEncoder()
        >>> emb = encoder.encode("kem d∆∞·ª°ng da cho da d·∫ßu")
        >>> embeddings = encoder.encode_batch(["query1", "query2"])
    """
    
    _instance: Optional['QueryEncoder'] = None
    _lock = threading.Lock()
    
    def __new__(cls, *args, **kwargs):
        """Singleton pattern for resource efficiency."""
        with cls._lock:
            if cls._instance is None:
                cls._instance = super().__new__(cls)
                cls._instance._initialized = False
            return cls._instance
    
    def __init__(
        self,
        model_name: str = "AITeamVN/Vietnamese_Embedding",
        max_length: int = 256,
        cache_size: int = 1000,
        device: str = "cpu",
        abbreviations: Optional[Dict[str, str]] = None
    ):
        """
        Initialize QueryEncoder.
        
        Args:
            model_name: HuggingFace model name for PhoBERT
            max_length: Maximum sequence length for tokenization
            cache_size: Size of LRU cache for query embeddings
            device: Device for model inference ('cpu' or 'cuda')
            abbreviations: Additional abbreviation mappings
        """
```

#### Vietnamese Abbreviations Mapping:

```python
VIETNAMESE_ABBREVIATIONS = {
    # Product abbreviations
    'sp': 's·∫£n ph·∫©m',
    'kem dc': 'kem d∆∞·ª°ng da',
    'kem dd': 'kem d∆∞·ª°ng da',
    'srm': 's·ªØa r·ª≠a m·∫∑t',
    'tbc': 't·∫©y bong ch·∫øt',
    'tdc': 't·∫©y da ch·∫øt',
    'kcn': 'kem ch·ªëng n·∫Øng',
    'cn': 'ch·ªëng n·∫Øng',
    'nc': 'n∆∞·ªõc',
    'nht': 'n∆∞·ªõc hoa h·ªìng',
    
    # Skin type abbreviations
    'dn': 'da nh·ªùn',
    'dk': 'da kh√¥',
    'dh': 'da h·ªón h·ª£p',
    'dnc': 'da nh·∫°y c·∫£m',
    'dm': 'da m·ª•n',
    
    # Common abbreviations
    'ko': 'kh√¥ng',
    'dc': 'ƒë∆∞·ª£c',
    'vs': 'v·ªõi',
    'cx': 'c≈©ng',
    'ntn': 'nh∆∞ th·∫ø n√†o',
}
```

#### Ph∆∞∆°ng th·ª©c quan tr·ªçng:

##### `preprocess_query()` - Ti·ªÅn x·ª≠ l√Ω ti·∫øng Vi·ªát

```python
def preprocess_query(self, query: str) -> str:
    """
    Preprocess Vietnamese query text.
    
    Steps:
    1. Lowercase and strip whitespace
    2. Expand abbreviations
    3. Normalize whitespace
    4. Remove special characters (keep Vietnamese)
    
    Args:
        query: Raw query text
    
    Returns:
        Preprocessed query string
    """
```

##### `encode()` - Encode m·ªôt query

```python
def encode(
    self,
    query: str,
    normalize: bool = True,
    use_cache: bool = True
) -> np.ndarray:
    """
    Encode a single query to embedding.
    
    Args:
        query: Text query (Vietnamese)
        normalize: L2 normalize the embedding for cosine similarity
        use_cache: Use LRU cache for repeated queries
    
    Returns:
        np.ndarray of shape (embedding_dim,)
    """
```

##### `encode_batch()` - Encode nhi·ªÅu queries

```python
def encode_batch(
    self,
    queries: List[str],
    normalize: bool = True,
    batch_size: int = 32,
    show_progress: bool = False
) -> np.ndarray:
    """
    Encode multiple queries efficiently with batching.
    
    Args:
        queries: List of text queries
        normalize: L2 normalize embeddings
        batch_size: Batch size for encoding
        show_progress: Show progress bar (requires tqdm)
    
    Returns:
        np.ndarray of shape (num_queries, embedding_dim)
    """
```

#### LRU Cache Implementation:

```python
class LRUCache:
    """Simple LRU cache for query embeddings."""
    
    def __init__(self, capacity: int = 1000):
        self.capacity = capacity
        self.cache: OrderedDict[str, np.ndarray] = OrderedDict()
        self._lock = threading.Lock()
    
    def get(self, key: str) -> Optional[np.ndarray]:
        """Get item from cache, moving to end if found."""
    
    def put(self, key: str, value: np.ndarray) -> None:
        """Put item in cache, evicting oldest if at capacity."""
    
    def stats(self) -> Dict[str, int]:
        """Return cache statistics."""
        return {'size': len(self.cache), 'capacity': self.capacity}
```

---

## Th√†nh Ph·∫ßn 2: SearchIndex ‚úÖ

### Module: `service/search/search_index.py`

**M√¥ t·∫£**: Index cho t√¨m ki·∫øm similarity nhanh, h·ªó tr·ª£ exact search v√† FAISS ANN.

#### T√≠nh nƒÉng ch√≠nh:
1. **Exact cosine similarity search**: Cho catalog nh·ªè (<5K products)
2. **FAISS ANN search**: Cho catalog l·ªõn, h·ªó tr·ª£ flat, ivf, hnsw
3. **Metadata filtering**: L·ªçc theo brand, category, price range
4. **Thread-safe operations**: An to√†n cho multi-threading

```python
class SearchIndex:
    """
    Search index for semantic product search.
    
    Features:
    - Exact cosine similarity search (for small catalogs)
    - FAISS ANN search (optional, for large catalogs >5K items)
    - Metadata filtering (brand, category, price range)
    - Thread-safe operations
    - Integration with PhoBERTEmbeddingLoader
    
    Example:
        >>> index = SearchIndex()
        >>> index.build_index()
        >>> results = index.search(query_embedding, topk=10)
        >>> results = index.search_with_filter(query_embedding, filters={'brand': 'Innisfree'})
    """
    
    def __init__(
        self,
        phobert_loader=None,
        product_metadata=None,
        use_faiss: bool = False,
        faiss_index_type: str = "flat",
        auto_build: bool = False
    ):
        """
        Initialize SearchIndex.
        
        Args:
            phobert_loader: PhoBERTEmbeddingLoader instance
            product_metadata: DataFrame with product info
            use_faiss: Use FAISS for ANN search (faster for large catalogs)
            faiss_index_type: FAISS index type ('flat', 'ivf', 'hnsw')
            auto_build: Automatically build index on init
        """
```

#### Ph∆∞∆°ng th·ª©c quan tr·ªçng:

##### `build_index()` - X√¢y d·ª±ng index

```python
def build_index(self) -> None:
    """
    Build search index from embeddings.
    
    Loads embeddings from PhoBERTEmbeddingLoader and builds
    necessary indices for fast similarity search.
    """
```

##### `_build_faiss_index()` - X√¢y d·ª±ng FAISS index

```python
def _build_faiss_index(self) -> None:
    """
    Build FAISS index for approximate nearest neighbor search.
    
    Supported index types:
    - flat: Exact search (brute force) - good for <10K items
    - ivf: IVF index - good for 10K-1M items
    - hnsw: HNSW - fast approximate search
    """
```

##### `_build_metadata_indices()` - X√¢y d·ª±ng inverted indices

```python
def _build_metadata_indices(self) -> None:
    """
    Build inverted indices for metadata filtering.
    
    Creates:
    - brand_index: Dict[str, Set[int]] - brand ‚Üí product_ids
    - category_index: Dict[str, Set[int]] - category ‚Üí product_ids
    - price_data: Dict[int, float] - product_id ‚Üí price
    """
```

##### `search()` - T√¨m ki·∫øm c∆° b·∫£n

```python
def search(
    self,
    query_embedding: np.ndarray,
    topk: int = 10,
    exclude_ids: Optional[Set[int]] = None
) -> List[Tuple[int, float]]:
    """
    Search for similar products.
    
    Args:
        query_embedding: Query embedding vector (should be normalized)
        topk: Number of results to return
        exclude_ids: Product IDs to exclude from results
    
    Returns:
        List of (product_id, similarity_score) tuples
    """
```

##### `search_with_filter()` - T√¨m ki·∫øm v·ªõi b·ªô l·ªçc

```python
def search_with_filter(
    self,
    query_embedding: np.ndarray,
    topk: int = 10,
    filters: Optional[Dict[str, Any]] = None,
    exclude_ids: Optional[Set[int]] = None
) -> List[Tuple[int, float]]:
    """
    Search with metadata filtering.
    
    Args:
        query_embedding: Query embedding
        topk: Number of results
        filters: Metadata filters:
            - 'brand': Brand name (string, case-insensitive)
            - 'category': Category/type name (string, case-insensitive)
            - 'min_price': Minimum price (float)
            - 'max_price': Maximum price (float)
        exclude_ids: IDs to exclude
    
    Returns:
        Filtered and ranked results as list of (product_id, score) tuples
    """
```

---

## Th√†nh Ph·∫ßn 3: SmartSearchService ‚úÖ

### Module: `service/search/smart_search.py`

**M√¥ t·∫£**: Service ch√≠nh cho t√¨m ki·∫øm s·∫£n ph·∫©m ng·ªØ nghƒ©a v·ªõi multi-signal reranking.

#### T√≠nh nƒÉng ch√≠nh:
1. **Text-to-product search**: T√¨m ki·∫øm b·∫±ng text ti·∫øng Vi·ªát
2. **Item-to-item similarity**: T√¨m s·∫£n ph·∫©m t∆∞∆°ng t·ª±
3. **User profile search**: T√¨m ki·∫øm d·ª±a tr√™n l·ªãch s·ª≠ ng∆∞·ªùi d√πng
4. **Multi-signal reranking**: K·∫øt h·ª£p semantic, popularity, quality, recency

```python
class SmartSearchService:
    """
    Smart Search Service for semantic product discovery.
    
    Features:
    - Text-to-product semantic search using PhoBERT
    - Item-to-item similarity search
    - User profile-based recommendations
    - Hybrid search with attribute filters
    - Multi-signal reranking (semantic, popularity, quality)
    
    Example:
        >>> service = SmartSearchService()
        >>> results = service.search("kem d∆∞·ª°ng da cho da d·∫ßu", topk=10)
        >>> similar = service.search_similar(product_id=123, topk=10)
    """
```

#### C·∫•u h√¨nh m·∫∑c ƒë·ªãnh:

```python
DEFAULT_CONFIG = {
    'default_topk': 10,
    'max_topk': 100,
    'min_semantic_score': 0.25,  # Minimum score to include in results
    'enable_rerank': True,
    'candidate_multiplier': 3,   # Fetch 3x candidates for reranking
    
    # Reranking weights
    'rerank_weights': {
        'semantic': 0.50,
        'popularity': 0.25,
        'quality': 0.15,
        'recency': 0.10
    },
    
    # User profile config
    'user_profile': {
        'strategy': 'weighted_mean',  # 'mean', 'weighted_mean', 'max'
        'max_history_items': 50       # Limit history items for profile
    }
}
```

#### Data Classes:

```python
@dataclass
class SearchResult:
    """Single search result."""
    product_id: int
    product_name: str
    semantic_score: float
    final_score: float
    brand: Optional[str] = None
    category: Optional[str] = None
    price: Optional[float] = None
    avg_rating: Optional[float] = None
    num_sold: Optional[int] = None
    signals: Optional[Dict[str, float]] = None
    rank: int = 0


@dataclass
class SearchResponse:
    """Search response container."""
    query: str
    results: List[SearchResult]
    count: int
    latency_ms: float
    method: str  # 'semantic', 'hybrid', 'similar_items', 'user_profile', 'popular'
    filters_applied: Optional[Dict[str, Any]] = None
```

#### Ph∆∞∆°ng th·ª©c quan tr·ªçng:

##### `search()` - T√¨m ki·∫øm ng·ªØ nghƒ©a

```python
def search(
    self,
    query: str,
    topk: int = 10,
    filters: Optional[Dict[str, Any]] = None,
    exclude_ids: Optional[Set[int]] = None,
    rerank: bool = True
) -> SearchResponse:
    """
    Semantic search for products.
    
    Args:
        query: Text query in Vietnamese (e.g., "kem d∆∞·ª°ng da cho da d·∫ßu")
        topk: Number of results to return
        filters: Attribute filters:
            - 'brand': Brand name (string)
            - 'category': Category name (string)
            - 'min_price': Minimum price (float)
            - 'max_price': Maximum price (float)
        exclude_ids: Product IDs to exclude from results
        rerank: Apply multi-signal reranking
    
    Returns:
        SearchResponse with ranked results
    
    Example:
        >>> results = service.search("kem d∆∞·ª°ng ·∫©m cho da kh√¥", topk=10)
        >>> results = service.search("s·ªØa r·ª≠a m·∫∑t", filters={'brand': 'innisfree'})
    """
```

##### `search_similar()` - T√¨m s·∫£n ph·∫©m t∆∞∆°ng t·ª±

```python
def search_similar(
    self,
    product_id: int,
    topk: int = 10,
    exclude_self: bool = True,
    exclude_ids: Optional[Set[int]] = None
) -> SearchResponse:
    """
    Find products similar to a given product.
    
    Uses PhoBERT embeddings for semantic similarity.
    
    Args:
        product_id: Source product ID
        topk: Number of similar products to return
        exclude_self: Exclude source product from results
        exclude_ids: Additional IDs to exclude
    
    Returns:
        SearchResponse with similar products
    """
```

##### `search_by_user_profile()` - T√¨m theo h·ªì s∆° ng∆∞·ªùi d√πng

```python
def search_by_user_profile(
    self,
    user_history: List[int],
    topk: int = 10,
    exclude_history: bool = True,
    filters: Optional[Dict[str, Any]] = None,
    weights: Optional[List[float]] = None
) -> SearchResponse:
    """
    Search products similar to user's interaction history.
    
    Computes a user profile embedding from history and finds similar products.
    Useful for cold-start personalization based on browsing history.
    
    Args:
        user_history: List of product IDs user has interacted with
        topk: Number of results
        exclude_history: Exclude products from history in results
        filters: Attribute filters
        weights: Optional weights for each history item (e.g., recency, rating)
    
    Returns:
        SearchResponse with personalized recommendations
    """
```

##### `_rerank_results()` - Multi-signal reranking

```python
def _rerank_results(
    self,
    raw_results: List[Tuple[int, float]],
    topk: int
) -> List[SearchResult]:
    """
    Rerank results using multiple signals.
    
    Signals:
    - semantic: Embedding similarity (from search)
    - popularity: num_sold_time or popularity_score
    - quality: avg_rating or quality_score
    - recency: Product freshness (placeholder)
    
    C√¥ng th·ª©c:
        final_score = Œ£ weight_i √ó signal_i
    
    M·∫∑c ƒë·ªãnh:
        semantic=0.50, popularity=0.25, quality=0.15, recency=0.10
    """
```

---

## Th√†nh Ph·∫ßn 4: API Endpoints ‚úÖ

### Module: `service/api.py`

#### Request/Response Models:

```python
class SearchRequest(APIBaseModel):
    """Semantic search request."""
    query: str = Field(..., min_length=1, max_length=500, description="Search query in Vietnamese")
    topk: int = Field(default=10, ge=1, le=100, description="Number of results")
    filters: Optional[Dict[str, Any]] = Field(
        default=None,
        description="Attribute filters: {brand, category, min_price, max_price}"
    )
    rerank: bool = Field(default=True, description="Apply hybrid reranking")


class SearchSimilarRequest(APIBaseModel):
    """Similar products search request."""
    product_id: int = Field(..., description="Product ID to find similar products")
    topk: int = Field(default=10, ge=1, le=50, description="Number of similar products")
    exclude_self: bool = Field(default=True, description="Exclude the query product from results")


class SearchByProfileRequest(APIBaseModel):
    """Search based on user profile/history."""
    product_history: List[int] = Field(..., min_length=1, description="List of product IDs user has interacted with")
    topk: int = Field(default=10, ge=1, le=100, description="Number of results")
    exclude_history: bool = Field(default=True, description="Exclude products in history from results")
    filters: Optional[Dict[str, Any]] = Field(default=None, description="Attribute filters")


class SearchResultItem(APIBaseModel):
    """Single search result item."""
    rank: int
    product_id: int
    product_name: str
    brand: Optional[str]
    category: Optional[str]
    price: Optional[float]
    avg_rating: Optional[float]
    num_sold: Optional[int]
    semantic_score: float
    final_score: float


class SearchResponse(APIBaseModel):
    """Search response."""
    query: str
    results: List[SearchResultItem]
    count: int
    method: str
    latency_ms: float
    available_filters: Optional[Dict[str, Any]] = None
```

#### Endpoints:

##### `POST /search` - T√¨m ki·∫øm s·∫£n ph·∫©m

```python
@app.post("/search", response_model=SearchResponse)
async def search_products(request: Request, search_request: SearchRequest):
    """
    Smart semantic search for products.
    
    Uses PhoBERT embeddings for Vietnamese semantic search.
    Supports attribute filtering and multi-signal reranking.
    
    Example:
        POST /search
        {
            "query": "kem d∆∞·ª°ng da cho da d·∫ßu",
            "topk": 10,
            "filters": {"brand": "innisfree"},
            "rerank": true
        }
    """
```

##### `POST /search/similar` - T√¨m s·∫£n ph·∫©m t∆∞∆°ng t·ª±

```python
@app.post("/search/similar", response_model=SearchResponse)
async def search_similar_products(request: SimilarSearchRequest):
    """
    Find products similar to a given product.
    
    Uses PhoBERT embeddings for item-item similarity.
    
    Example:
        POST /search/similar
        {
            "product_id": 123,
            "topk": 10,
            "exclude_self": true
        }
    """
```

##### `POST /search/profile` - T√¨m theo h·ªì s∆° ng∆∞·ªùi d√πng

```python
@app.post("/search/profile", response_model=SearchResponse)
async def search_by_profile(request: SearchByProfileRequest):
    """
    Search products based on user browsing/interaction history.
    
    Useful for cold-start personalization.
    
    Example:
        POST /search/profile
        {
            "product_history": [123, 456, 789],
            "topk": 10,
            "exclude_history": true
        }
    """
```

##### `GET /search/filters` - L·∫•y danh s√°ch b·ªô l·ªçc

```python
@app.get("/search/filters")
async def get_search_filters():
    """
    Get available filter options.
    
    Returns:
        - brands: List of available brand names
        - categories: List of available category names
        - price_range: (min_price, max_price)
    """
```

##### `GET /search/stats` - Th·ªëng k√™ search service

```python
@app.get("/search/stats")
async def get_search_stats():
    """
    Get search service statistics.
    
    Returns:
        - total_searches: Total number of searches
        - avg_latency_ms: Average search latency
        - errors: Number of errors
        - index stats: Index statistics
        - encoder stats: Encoder statistics
    """
```

---

## Th√†nh Ph·∫ßn 5: Test Script ‚úÖ

### Module: `service/search/test_search_features.py`

```python
"""
Test script ƒë·ªÉ verify c√°c t√≠nh nƒÉng c·ªßa module search ho·∫°t ƒë·ªông ƒë√∫ng.

Ch·∫°y script n√†y ƒë·ªÉ ki·ªÉm tra:
- QueryEncoder encoding
- SearchIndex search functionality
- SmartSearchService c√°c t√≠nh nƒÉng t√¨m ki·∫øm

Usage:
    python service/search/test_search_features.py
"""

def test_query_encoder():
    """Test QueryEncoder functionality."""
    # Test 1: Preprocessing v·ªõi Vietnamese text
    # Test 2: Encoding (n·∫øu model c√≥ s·∫µn)
    # Test 3: Cache functionality

def test_search_index():
    """Test SearchIndex functionality."""
    # Test 1: Initialization
    # Test 2: Build index
    # Test 3: Available filters

def test_smart_search_service():
    """Test SmartSearchService functionality."""
    # Test 1: Initialization
    # Test 2: Text search
    # Test 3: Similar items search
    # Test 4: Service stats
```

---

## C·∫•u Tr√∫c Th∆∞ M·ª•c

```
service/
‚îú‚îÄ search/
‚îÇ  ‚îú‚îÄ __init__.py              # Module exports
‚îÇ  ‚îú‚îÄ query_encoder.py         # QueryEncoder class
‚îÇ  ‚îú‚îÄ search_index.py          # SearchIndex class
‚îÇ  ‚îú‚îÄ smart_search.py          # SmartSearchService class
‚îÇ  ‚îî‚îÄ test_search_features.py  # Test script
‚îú‚îÄ api.py                      # API endpoints (updated)
‚îî‚îÄ recommender/
   ‚îî‚îÄ phobert_loader.py        # Shared PhoBERT embeddings
```

---

## H∆∞·ªõng D·∫´n S·ª≠ D·ª•ng

### 1. T√¨m ki·∫øm s·∫£n ph·∫©m b·∫±ng text

```python
from service.search import get_search_service

service = get_search_service()

# T√¨m ki·∫øm ƒë∆°n gi·∫£n
results = service.search("kem d∆∞·ª°ng da cho da d·∫ßu", topk=10)
print(f"T√¨m th·∫•y: {results.count} s·∫£n ph·∫©m")
print(f"Latency: {results.latency_ms:.2f}ms")

for item in results.results:
    print(f"  {item.rank}. {item.product_name}")
    print(f"     Score: {item.final_score:.3f}")
    print(f"     Brand: {item.brand}")

# T√¨m ki·∫øm v·ªõi b·ªô l·ªçc
results = service.search(
    "s·ªØa r·ª≠a m·∫∑t",
    topk=10,
    filters={
        'brand': 'innisfree',
        'max_price': 300000
    }
)
```

### 2. T√¨m s·∫£n ph·∫©m t∆∞∆°ng t·ª±

```python
# T√¨m s·∫£n ph·∫©m t∆∞∆°ng t·ª± v·ªõi product_id=123
similar = service.search_similar(
    product_id=123,
    topk=10,
    exclude_self=True
)

for item in similar.results:
    print(f"  {item.product_name}: {item.semantic_score:.3f}")
```

### 3. T√¨m ki·∫øm theo l·ªãch s·ª≠ ng∆∞·ªùi d√πng

```python
# Ng∆∞·ªùi d√πng ƒë√£ xem c√°c s·∫£n ph·∫©m n√†y
user_history = [101, 102, 103, 104]

# T√¨m s·∫£n ph·∫©m ph√π h·ª£p v·ªõi s·ªü th√≠ch
recommendations = service.search_by_user_profile(
    user_history=user_history,
    topk=10,
    exclude_history=True
)

print(f"G·ª£i √Ω cho ng∆∞·ªùi d√πng: {recommendations.count} s·∫£n ph·∫©m")
```

### 4. S·ª≠ d·ª•ng API

```bash
# T√¨m ki·∫øm
curl -X POST http://localhost:8000/search \
  -H "Content-Type: application/json" \
  -d '{"query": "kem d∆∞·ª°ng da", "topk": 10}'

# T√¨m s·∫£n ph·∫©m t∆∞∆°ng t·ª±
curl -X POST http://localhost:8000/search/similar \
  -H "Content-Type: application/json" \
  -d '{"product_id": 123, "topk": 10}'

# L·∫•y danh s√°ch b·ªô l·ªçc
curl http://localhost:8000/search/filters

# Xem th·ªëng k√™
curl http://localhost:8000/search/stats
```

---

## T√≠ch H·ª£p Li√™n Task

| Task | ƒêi·ªÉm t√≠ch h·ª£p | Tr·∫°ng th√°i |
|------|---------------|------------|
| Task 05 (Serving) | Chia s·∫ª `PhoBERTEmbeddingLoader` singleton | ‚úÖ |
| Task 08 (Hybrid Reranking) | Reuse reranking logic v√† normalization | ‚úÖ |
| Task 06 (Monitoring) | Log search queries v√† latencies | ‚úÖ |
| Task 01 (Data Layer) | S·ª≠ d·ª•ng product metadata enriched | ‚úÖ |

---

## M·ª•c Ti√™u Hi·ªáu NƒÉng

| Metric | M·ª•c ti√™u | Ghi ch√∫ |
|--------|----------|---------|
| Latency P50 | <100ms | Median response |
| Latency P95 | <300ms | 95% requests |
| Latency P99 | <500ms | SLA target |
| Cache hit rate | >70% | Cho repeated queries |
| Min semantic score | 0.25 | Threshold ƒë·ªÉ include |

---

## Ti√™u Ch√≠ Th√†nh C√¥ng ‚úÖ ƒê·∫†T ƒê∆Ø·ª¢C

- [x] QueryEncoder v·ªõi singleton pattern v√† LRU cache
- [x] Vietnamese preprocessing v·ªõi abbreviation expansion
- [x] SearchIndex h·ªó tr·ª£ exact v√† FAISS search
- [x] Metadata filtering (brand, category, price)
- [x] SmartSearchService v·ªõi multi-signal reranking
- [x] Text search, similar items, user profile search
- [x] API endpoints ƒë·∫ßy ƒë·ªß v·ªõi Pydantic models
- [x] Thread-safe operations
- [x] Test script cho t·∫•t c·∫£ components
- [x] T√≠ch h·ª£p v·ªõi PhoBERTEmbeddingLoader c√≥ s·∫µn

---

## M·ªü R·ªông T∆∞∆°ng Lai

1. **Query Understanding**:
   - Intent classification (browse, compare, specific search)
   - Query expansion with synonyms
   - Spell correction for Vietnamese

2. **Personalization**:
   - Learn from search click history
   - User preference weighting
   - Session-based personalization

3. **Advanced Ranking**:
   - Learning-to-rank models
   - A/B testing framework
   - Dynamic weight adjustment

4. **Scalability**:
   - Distributed FAISS index
   - Redis caching layer
   - Async query processing

---

**Created**: 2025-11-26  
**Updated**: 2025-11-30  
**Status**: ‚úÖ Ho√†n th√†nh  
**Priority**: High
